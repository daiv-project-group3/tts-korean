{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:00:12.207800Z",
     "start_time": "2024-11-19T15:59:45.970982Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install numpy==1.25.2",
   "id": "b223f4c7cdf2ee95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.25.2\n",
      "  Using cached numpy-1.25.2-cp311-cp311-win_amd64.whl.metadata (5.7 kB)\n",
      "Using cached numpy-1.25.2-cp311-cp311-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed numpy-1.25.2\n"
     ]
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:01:48.633358Z",
     "start_time": "2024-11-19T16:01:48.528680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numba\n",
    "print(numba.__version__)\n"
   ],
   "id": "e1969048f30d0731",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.0 or less. Got NumPy 2.1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[159], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(numba\u001B[38;5;241m.\u001B[39m__version__)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:59\u001B[0m\n\u001B[0;32m     54\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     55\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscipy\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     56\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m---> 59\u001B[0m \u001B[43m_ensure_critical_deps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# END DO NOT MOVE\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_versions\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:45\u001B[0m, in \u001B[0;36m_ensure_critical_deps\u001B[1;34m()\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m numpy_version \u001B[38;5;241m>\u001B[39m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     43\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba needs NumPy 2.0 or less. Got NumPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     44\u001B[0m            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Numba needs NumPy 2.0 or less. Got NumPy 2.1."
     ]
    }
   ],
   "execution_count": 159
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:14.521362Z",
     "start_time": "2024-11-19T16:02:07.912690Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install --upgrade numba",
   "id": "1f7f488fba7b883c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\seungju\\python\\python311\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\seungju\\python\\python311\\lib\\site-packages (from numba) (0.43.0)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\users\\seungju\\python\\python311\\lib\\site-packages (from numba) (1.25.2)\n"
     ]
    }
   ],
   "execution_count": 160
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:19.007417Z",
     "start_time": "2024-11-19T16:02:19.001795Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "from jamo import hangul_to_jamo\n",
    "import librosa.feature\n",
    "from torch.utils.data import Dataset\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio"
   ],
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:19.526308Z",
     "start_time": "2024-11-19T16:02:19.518883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "id": "855f1d8671786fc4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:19.945152Z",
     "start_time": "2024-11-19T16:02:19.936259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_sequence(text):\n",
    "    # 한글 자모 분해\n",
    "    sequence = []\n",
    "    for char in text:\n",
    "        if '가' <= char <= '힣':\n",
    "            jamos = list(hangul_to_jamo(char))\n",
    "            sequence.extend(jamos)\n",
    "        else:\n",
    "            sequence.append(char)\n",
    "    return sequence"
   ],
   "id": "8b1ec414a8722034",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:20.320711Z",
     "start_time": "2024-11-19T16:02:20.313649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # 예시: 데이터셋의 모든 텍스트를 수집\n",
    "# all_texts = []\n",
    "# metadata_path = '여기에 파일'\n",
    "#\n",
    "# with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "#     for line in f:\n",
    "#         parts = line.strip().split('|')\n",
    "#         if len(parts) >= 2:\n",
    "#             path, text = parts[0], parts[1]\n",
    "#             all_texts.append(text)\n",
    "#\n",
    "# # 모든 텍스트에서 고유한 토큰 추출\n",
    "# unique_tokens = set()\n",
    "# for text in all_texts:\n",
    "#     sequence = text_to_sequence(text)\n",
    "#     unique_tokens.update(sequence)\n",
    "#\n",
    "# # 토큰과 인덱스 매핑\n",
    "# vocab = {token: idx for idx, token in enumerate(sorted(unique_tokens))}\n",
    "# vocab['<pad>'] = len(vocab)\n",
    "# vocab['<unk>'] = len(vocab)\n"
   ],
   "id": "5c97f2d7f2cde741",
   "outputs": [],
   "execution_count": 164
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:20.395058Z",
     "start_time": "2024-11-19T16:02:20.386003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mask_from_lengths(lengths, max_len=None):\n",
    "    batch_size = lengths.size(0)\n",
    "    if max_len is None:\n",
    "        max_len = torch.max(lengths).item()\n",
    "    ids = torch.arange(0, max_len, device=lengths.device).unsqueeze(0).expand(batch_size, -1)\n",
    "    mask = ids < lengths.unsqueeze(1)\n",
    "    return mask  # (batch_size, max_len)"
   ],
   "id": "7aca187df671f0fb",
   "outputs": [],
   "execution_count": 165
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:20.435842Z",
     "start_time": "2024-11-19T16:02:20.424393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_wav(path, sr=22050):\n",
    "    wav, _ = librosa.load(path, sr=sr)\n",
    "    return wav\n",
    "\n",
    "# 오디오 전처리 함수\n",
    "def wav_to_mel(wav, sr=22050, n_fft=1024, hop_length=256, win_length=1024, n_mels=80, fmin=0, fmax=8000):\n",
    "    # STFT\n",
    "    stft = librosa.stft(wav, n_fft=n_fft, hop_length=hop_length, win_length=win_length)\n",
    "    # 멜 스펙트로그램\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(S=np.abs(stft)**2,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     fmin=fmin, fmax=fmax)\n",
    "    # 로그 스케일\n",
    "    mel_spectrogram = np.log(np.clip(mel_spectrogram, a_min=1e-5, a_max=None))\n",
    "    return mel_spectrogram\n",
    "\n",
    "def normalize_mel(mel_spectrogram):\n",
    "    # 정규화: [-4, 4] -> [0, 1]\n",
    "    mel_spectrogram = np.clip(mel_spectrogram, a_min=-4, a_max=4)\n",
    "    mel_spectrogram = (mel_spectrogram + 4) / 8\n",
    "    return mel_spectrogram"
   ],
   "id": "22f2db585f32c26f",
   "outputs": [],
   "execution_count": 166
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:20.483422Z",
     "start_time": "2024-11-19T16:02:20.464014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class KSSDataset(Dataset):\n",
    "    def __init__(self, vocab, split='train', valid_size=0.1, seed=42, target_sr=22050):\n",
    "        super().__init__()\n",
    "\n",
    "        # 데이터셋 로드\n",
    "        dataset = load_dataset(\"Bingsu/KSS_Dataset\")\n",
    "        full_dataset = dataset['train']\n",
    "\n",
    "        # train/valid 분할\n",
    "        train_idx, valid_idx = train_test_split(\n",
    "            range(len(full_dataset)),\n",
    "            test_size=valid_size,\n",
    "            random_state=seed\n",
    "        )\n",
    "\n",
    "        # split에 따라 인덱스 선택\n",
    "        self.indices = train_idx if split == 'train' else valid_idx\n",
    "        self.dataset = full_dataset\n",
    "        self.vocab = vocab\n",
    "        self.target_sr = target_sr  # 타겟 샘플링 레이트\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.indices[idx]\n",
    "        item = self.dataset[real_idx]\n",
    "\n",
    "        # 텍스트 처리 (컬럼명 수정)\n",
    "        transcription = item['original_script']\n",
    "        sequence = text_to_sequence(transcription)\n",
    "        sequence = [self.vocab.get(char, self.vocab['<unk>']) for char in sequence]\n",
    "        sequence = torch.LongTensor(sequence)\n",
    "        input_length = sequence.size(0)\n",
    "\n",
    "        # 오디오 로드 및 리샘플링\n",
    "        wav = item['audio']['array']  # numpy 배열\n",
    "        original_sr = item['audio']['sampling_rate']\n",
    "\n",
    "        if original_sr != self.target_sr:\n",
    "            wav = librosa.resample(wav, orig_sr=original_sr, target_sr=self.target_sr)\n",
    "\n",
    "        # 멜 스펙트로그램 변환\n",
    "        mel = wav_to_mel(wav, sr=self.target_sr)\n",
    "        mel = normalize_mel(mel)\n",
    "        mel = torch.FloatTensor(mel)\n",
    "        mel = mel.transpose(0, 1)  # (시간 축, 멜 밴드 수)\n",
    "        mel_length = mel.size(0)\n",
    "\n",
    "        return sequence, input_length, mel, mel_length"
   ],
   "id": "ba9d1c96ea35c25f",
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:28.775929Z",
     "start_time": "2024-11-19T16:02:20.506657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = load_dataset(\"Bingsu/KSS_Dataset\")\n",
    "\n",
    "# 모든 텍스트 수집 (컬럼명 수정)\n",
    "all_texts = dataset[\"train\"][\"original_script\"]\n",
    "\n",
    "# 어휘 사전 생성\n",
    "unique_tokens = set()\n",
    "for text in all_texts:\n",
    "    sequence = text_to_sequence(text)\n",
    "    unique_tokens.update(sequence)\n",
    "\n",
    "vocab = {token: idx for idx, token in enumerate(sorted(unique_tokens))}\n",
    "vocab['<pad>'] = len(vocab)\n",
    "vocab['<unk>'] = len(vocab)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = KSSDataset(vocab, split='train')\n",
    "valid_dataset = KSSDataset(vocab, split='valid')\n"
   ],
   "id": "b39a1991503a6fea",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:28.788761Z",
     "start_time": "2024-11-19T16:02:28.784358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def __getitem__(self, idx):\n",
    "    try:\n",
    "        # 기존 코드\n",
    "        real_idx = self.indices[idx]\n",
    "        item = self.dataset[real_idx]\n",
    "\n",
    "        # 텍스트 처리\n",
    "        transcription = item['original_script']\n",
    "        sequence = text_to_sequence(transcription)\n",
    "        sequence = [self.vocab.get(char, self.vocab['<unk>']) for char in sequence]\n",
    "        sequence = torch.LongTensor(sequence)\n",
    "        input_length = sequence.size(0)\n",
    "\n",
    "        # 오디오 로드 및 리샘플링\n",
    "        wav = item['audio']['array']  # numpy 배열\n",
    "        original_sr = item['audio']['sampling_rate']\n",
    "\n",
    "        if original_sr != self.target_sr:\n",
    "            wav = librosa.resample(wav, orig_sr=original_sr, target_sr=self.target_sr)\n",
    "\n",
    "        # 멜 스펙트로그램 변환\n",
    "        mel = wav_to_mel(wav, sr=self.target_sr)\n",
    "        mel = normalize_mel(mel)\n",
    "        mel = torch.FloatTensor(mel)\n",
    "        mel = mel.transpose(0, 1)  # (시간 축, 멜 밴드 수)\n",
    "        mel_length = mel.size(0)\n",
    "\n",
    "        return sequence, input_length, mel, mel_length\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "        raise e  # 예외를 다시 발생시켜 어디에서 문제가 발생하는지 확인\n"
   ],
   "id": "43edb15adaaad61c",
   "outputs": [],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:28.832802Z",
     "start_time": "2024-11-19T16:02:28.796022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# collate_fn 함수\n",
    "def collate_fn(batch):\n",
    "    try:\n",
    "        sequences, input_lengths, mels, mel_lengths = zip(*batch)\n",
    "        # 텍스트 시퀀스 패딩\n",
    "        max_input_len = max(input_lengths)\n",
    "        padded_sequences = torch.zeros(len(sequences), max_input_len, dtype=torch.long)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            padded_sequences[i, :seq.size(0)] = seq\n",
    "        # 멜 스펙트로그램 패딩\n",
    "        max_mel_len = max(mel_lengths)\n",
    "        num_mels = mels[0].size(1)\n",
    "        padded_mels = torch.zeros(len(mels), max_mel_len, num_mels)\n",
    "        for i, mel in enumerate(mels):\n",
    "            padded_mels[i, :mel.size(0), :] = mel\n",
    "        # 길이 정보를 텐서로 변환\n",
    "        input_lengths = torch.LongTensor(input_lengths)\n",
    "        mel_lengths = torch.LongTensor(mel_lengths)\n",
    "        return padded_sequences, input_lengths, padded_mels, mel_lengths\n",
    "    except Exception as e:\n",
    "        print(f\"Error in collate_fn: {e}\")\n",
    "        raise e\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn, num_workers=4)"
   ],
   "id": "d4a5d1bb67fa8111",
   "outputs": [],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.011802Z",
     "start_time": "2024-11-19T16:02:28.843430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = train_dataset[0]\n",
    "print(sample)"
   ],
   "id": "b1898c8582a026be",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.0 or less. Got NumPy 2.1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[171], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m sample \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(sample)\n",
      "Cell \u001B[1;32mIn[167], line 27\u001B[0m, in \u001B[0;36mKSSDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     26\u001B[0m     real_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]\n\u001B[1;32m---> 27\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mreal_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# 텍스트 처리 (컬럼명 수정)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     transcription \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal_script\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2760\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2761\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:2747\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2745\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2746\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[1;32m-> 2747\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2748\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2749\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2750\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:639\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:403\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable, query_type: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 403\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_row\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_column(pa_table)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:444\u001B[0m, in \u001B[0;36mPythonFormatter.format_row\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LazyRow(pa_table, \u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    443\u001B[0m row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_row(pa_table)\n\u001B[1;32m--> 444\u001B[0m row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_features_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_row\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m row\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:222\u001B[0m, in \u001B[0;36mPythonFeaturesDecoder.decode_row\u001B[1;34m(self, row)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_row\u001B[39m(\u001B[38;5;28mself\u001B[39m, row: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;28;01melse\u001B[39;00m row\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:2044\u001B[0m, in \u001B[0;36mFeatures.decode_example\u001B[1;34m(self, example, token_per_repo_id)\u001B[0m\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_example\u001B[39m(\u001B[38;5;28mself\u001B[39m, example: \u001B[38;5;28mdict\u001B[39m, token_per_repo_id: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2031\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001B[39;00m\n\u001B[0;32m   2032\u001B[0m \n\u001B[0;32m   2033\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2041\u001B[0m \u001B[38;5;124;03m        `dict[str, Any]`\u001B[39;00m\n\u001B[0;32m   2042\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2044\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m{\u001B[49m\n\u001B[0;32m   2045\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2046\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_column_requires_decoding\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   2047\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\n\u001B[0;32m   2048\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mzip_dict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2049\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\n\u001B[0;32m   2050\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2051\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:2045\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_example\u001B[39m(\u001B[38;5;28mself\u001B[39m, example: \u001B[38;5;28mdict\u001B[39m, token_per_repo_id: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2031\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001B[39;00m\n\u001B[0;32m   2032\u001B[0m \n\u001B[0;32m   2033\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2041\u001B[0m \u001B[38;5;124;03m        `dict[str, Any]`\u001B[39;00m\n\u001B[0;32m   2042\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   2044\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m-> 2045\u001B[0m         column_name: \u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2046\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_column_requires_decoding[column_name]\n\u001B[0;32m   2047\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m value\n\u001B[0;32m   2048\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m column_name, (feature, value) \u001B[38;5;129;01min\u001B[39;00m zip_dict(\n\u001B[0;32m   2049\u001B[0m             {key: value \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m example}, example\n\u001B[0;32m   2050\u001B[0m         )\n\u001B[0;32m   2051\u001B[0m     }\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:1405\u001B[0m, in \u001B[0;36mdecode_nested_example\u001B[1;34m(schema, obj, token_per_repo_id)\u001B[0m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(schema, (Audio, Image, Video)):\n\u001B[0;32m   1403\u001B[0m     \u001B[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001B[39;00m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m schema\u001B[38;5;241m.\u001B[39mdecode:\n\u001B[1;32m-> 1405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mschema\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\audio.py:191\u001B[0m, in \u001B[0;36mAudio.decode_example\u001B[1;34m(self, value, token_per_repo_id)\u001B[0m\n\u001B[0;32m    189\u001B[0m array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmono:\n\u001B[1;32m--> 191\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_mono\u001B[49m(array)\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate \u001B[38;5;241m!=\u001B[39m sampling_rate:\n\u001B[0;32m    193\u001B[0m     array \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mresample(array, orig_sr\u001B[38;5;241m=\u001B[39msampling_rate, target_sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:83\u001B[0m, in \u001B[0;36mattach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     81\u001B[0m submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     82\u001B[0m submod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(submod_path)\n\u001B[1;32m---> 83\u001B[0m attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m attr_to_modules[name]:\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:82\u001B[0m, in \u001B[0;36mattach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attr_to_modules:\n\u001B[0;32m     81\u001B[0m     submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 82\u001B[0m     submod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubmod_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1147\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msoxr\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mlazy\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jit, stencil, guvectorize\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_fftlib\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frames_to_samples, time_to_samples\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:59\u001B[0m\n\u001B[0;32m     54\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     55\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscipy\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     56\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m---> 59\u001B[0m \u001B[43m_ensure_critical_deps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# END DO NOT MOVE\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_versions\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:45\u001B[0m, in \u001B[0;36m_ensure_critical_deps\u001B[1;34m()\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m numpy_version \u001B[38;5;241m>\u001B[39m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     43\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba needs NumPy 2.0 or less. Got NumPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     44\u001B[0m            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Numba needs NumPy 2.0 or less. Got NumPy 2.1."
     ]
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.015808700Z",
     "start_time": "2024-11-19T15:57:12.022146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TacotronDataset(Dataset):\n",
    "    def __init__(self, metadata_path, vocab):\n",
    "        self.vocab = vocab\n",
    "        self.data = self.load_metadata(metadata_path)\n",
    "\n",
    "    def load_metadata(self, metadata_path):\n",
    "        data = []\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('|')\n",
    "                if len(parts) >= 2:\n",
    "                    path, text = parts[0], parts[1]\n",
    "                    data.append((path, text))\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path, text = self.data[idx]\n",
    "        # 텍스트 처리\n",
    "        sequence = text_to_sequence(text)\n",
    "        sequence = [self.vocab.get(char, self.vocab['<unk>']) for char in sequence]\n",
    "        sequence = torch.LongTensor(sequence)\n",
    "        input_length = sequence.size(0)\n",
    "        # 오디오 처리\n",
    "        wav = load_wav(path)\n",
    "        mel = wav_to_mel(wav)\n",
    "        mel = normalize_mel(mel)\n",
    "        mel = torch.FloatTensor(mel)\n",
    "        mel = mel.transpose(0, 1)  # (시간 축, 멜 밴드 수)\n",
    "        mel_length = mel.size(0)\n",
    "        return sequence, input_length, mel, mel_length\n"
   ],
   "id": "cc2ac5f7e61854a6",
   "outputs": [],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.017320400Z",
     "start_time": "2024-11-19T15:57:12.696072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def collate_fn(batch):\n",
    "#     sequences, input_lengths, mels, mel_lengths = zip(*batch)\n",
    "#     # 입력 시퀀스 패딩\n",
    "#     max_input_len = max(input_lengths)\n",
    "#     padded_sequences = torch.zeros(len(sequences), max_input_len, dtype=torch.long)\n",
    "#     for i, seq in enumerate(sequences):\n",
    "#         padded_sequences[i, :seq.size(0)] = seq\n",
    "#     # 멜 스펙트로그램 패딩\n",
    "#     max_mel_len = max(mel_lengths)\n",
    "#     num_mels = mels[0].size(1)\n",
    "#     padded_mels = torch.zeros(len(mels), max_mel_len, num_mels)\n",
    "#     for i, mel in enumerate(mels):\n",
    "#         padded_mels[i, :mel.size(0), :] = mel\n",
    "#     # 길이 텐서로 변환\n",
    "#     input_lengths = torch.LongTensor(input_lengths)\n",
    "#     mel_lengths = torch.LongTensor(mel_lengths)\n",
    "#     return padded_sequences, input_lengths, padded_mels, mel_lengths\n"
   ],
   "id": "5870ef28affefddd",
   "outputs": [],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.027843900Z",
     "start_time": "2024-11-19T15:57:13.227743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        conv_channels = 512\n",
    "        self.prenet = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, conv_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(conv_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(conv_channels, conv_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(conv_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(conv_channels, conv_channels, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(conv_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.lstm = nn.LSTM(conv_channels, 512, num_layers=1, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, seq_len, embedding_dim)\n",
    "        x = x.transpose(1, 2)  # (batch_size, embedding_dim, seq_len)\n",
    "        x = self.prenet(x)     # (batch_size, conv_channels, seq_len)\n",
    "        x = x.transpose(1, 2)  # (batch_size, seq_len, conv_channels)\n",
    "        outputs, _ = self.lstm(x)\n",
    "        return outputs  # (batch_size, seq_len, 512)\n"
   ],
   "id": "f78bb82c602cc293",
   "outputs": [],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.031841900Z",
     "start_time": "2024-11-19T15:57:13.823443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreNet(nn.Module):\n",
    "    def __init__(self, in_dim):\n",
    "        super(PreNet, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(in_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ],
   "id": "c8a60b65f07c9cd8",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.031841900Z",
     "start_time": "2024-11-19T15:57:14.437003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, attention_rnn_dim, encoder_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.query_layer = nn.Linear(attention_rnn_dim, 128)\n",
    "        self.memory_layer = nn.Linear(encoder_dim, 128)\n",
    "        self.v = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, attention_hidden_state, memory, mask):\n",
    "        # attention_hidden_state: (batch_size, attention_rnn_dim)\n",
    "        # memory: (batch_size, seq_len, encoder_dim)\n",
    "        # mask: (batch_size, seq_len)\n",
    "        processed_query = self.query_layer(attention_hidden_state).unsqueeze(1)  # (batch_size, 1, 128)\n",
    "        processed_memory = self.memory_layer(memory)  # (batch_size, seq_len, 128)\n",
    "        energies = self.v(torch.tanh(processed_query + processed_memory)).squeeze(-1)  # (batch_size, seq_len)\n",
    "        energies.data.masked_fill_(mask == 0, -float('inf'))\n",
    "        attention_weights = F.softmax(energies, dim=1)  # (batch_size, seq_len)\n",
    "        attention_context = torch.bmm(attention_weights.unsqueeze(1), memory).squeeze(1)  # (batch_size, encoder_dim)\n",
    "        return attention_context, attention_weights\n"
   ],
   "id": "1328724f649cf03b",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.031841900Z",
     "start_time": "2024-11-19T15:57:15.055288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.prenet = PreNet(80)\n",
    "        self.attention_rnn = nn.LSTMCell(256 + 512, 1024)\n",
    "        self.attention_layer = Attention(1024, 512)\n",
    "        self.decoder_rnn = nn.LSTMCell(1024 + 512, 1024)\n",
    "        self.linear_projection = nn.Linear(1024 + 512, 80)\n",
    "        self.stop_projection = nn.Linear(1024 + 512, 1)\n",
    "\n",
    "    def forward(self, memory, decoder_inputs, memory_lengths):\n",
    "        # memory: (batch_size, seq_len, 512)\n",
    "        # decoder_inputs: (batch_size, max_time, 80)\n",
    "        # memory_lengths: (batch_size)\n",
    "        batch_size = memory.size(0)\n",
    "        max_time = decoder_inputs.size(1)\n",
    "        device = memory.device\n",
    "\n",
    "        # 마스크 생성\n",
    "        mask = ~get_mask_from_lengths(memory_lengths, max_len=memory.size(1)).to(device)\n",
    "\n",
    "        # 초기화\n",
    "        attention_hidden = torch.zeros(batch_size, 1024).to(device)\n",
    "        attention_cell = torch.zeros(batch_size, 1024).to(device)\n",
    "        decoder_hidden = torch.zeros(batch_size, 1024).to(device)\n",
    "        decoder_cell = torch.zeros(batch_size, 1024).to(device)\n",
    "        attention_context = torch.zeros(batch_size, 512).to(device)\n",
    "        mel_outputs = []\n",
    "        stop_outputs = []\n",
    "\n",
    "        for t in range(max_time):\n",
    "            prenet_input = decoder_inputs[:, t, :]  # (batch_size, 80)\n",
    "            prenet_output = self.prenet(prenet_input)\n",
    "            # 어텐션 RNN\n",
    "            attention_rnn_input = torch.cat((prenet_output, attention_context), dim=-1)\n",
    "            attention_hidden, attention_cell = self.attention_rnn(attention_rnn_input, (attention_hidden, attention_cell))\n",
    "            # 어텐션 메커니즘\n",
    "            attention_context, attention_weights = self.attention_layer(attention_hidden, memory, mask)\n",
    "            # 디코더 RNN\n",
    "            decoder_rnn_input = torch.cat((attention_hidden, attention_context), dim=-1)\n",
    "            decoder_hidden, decoder_cell = self.decoder_rnn(decoder_rnn_input, (decoder_hidden, decoder_cell))\n",
    "            # 출력 계산\n",
    "            decoder_output = torch.cat((decoder_hidden, attention_context), dim=-1)\n",
    "            mel_output = self.linear_projection(decoder_output)\n",
    "            stop_output = self.stop_projection(decoder_output)\n",
    "            mel_outputs.append(mel_output.unsqueeze(1))\n",
    "            stop_outputs.append(stop_output.unsqueeze(1))\n",
    "\n",
    "        mel_outputs = torch.cat(mel_outputs, dim=1)  # (batch_size, max_time, 80)\n",
    "        stop_outputs = torch.cat(stop_outputs, dim=1)  # (batch_size, max_time, 1)\n",
    "        return mel_outputs, stop_outputs\n"
   ],
   "id": "449fe5e9ab76f673",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.031841900Z",
     "start_time": "2024-11-19T15:57:15.897640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PostNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PostNet, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        in_channels = [80] + [512] * 4\n",
    "        out_channels = [512] * 4 + [80]\n",
    "        for i in range(5):\n",
    "            self.layers.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv1d(in_channels[i], out_channels[i], kernel_size=5, padding=2),\n",
    "                    nn.BatchNorm1d(out_channels[i]),\n",
    "                    nn.Tanh() if i < 4 else nn.Identity(),\n",
    "                    nn.Dropout(0.5)\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (batch_size, 80, max_time)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = x.transpose(1, 2)  # (batch_size, max_time, 80)\n",
    "        return x\n"
   ],
   "id": "2cc29992539b37a",
   "outputs": [],
   "execution_count": 131
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.032842Z",
     "start_time": "2024-11-19T15:57:16.481833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Tacotron2(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=512):\n",
    "        super(Tacotron2, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.encoder = Encoder(embedding_dim)\n",
    "        self.decoder = Decoder()\n",
    "        self.postnet = PostNet()\n",
    "\n",
    "    def forward(self, text_inputs, mel_targets, input_lengths):\n",
    "        # 인코더\n",
    "        embedded_inputs = self.embedding(text_inputs)  # (batch_size, seq_len, embedding_dim)\n",
    "        encoder_outputs = self.encoder(embedded_inputs)\n",
    "\n",
    "        # 디코더 입력 준비\n",
    "        decoder_inputs = self._get_decoder_inputs(mel_targets)\n",
    "\n",
    "        # 디코더\n",
    "        mel_outputs, stop_outputs = self.decoder(encoder_outputs, decoder_inputs, input_lengths)\n",
    "\n",
    "        # 포스트넷\n",
    "        mel_outputs_postnet = mel_outputs + self.postnet(mel_outputs)\n",
    "\n",
    "        return mel_outputs, mel_outputs_postnet, stop_outputs\n",
    "\n",
    "    def _get_decoder_inputs(self, mel_targets):\n",
    "        go_frame = torch.zeros(mel_targets.size(0), 1, mel_targets.size(2)).to(mel_targets.device)\n",
    "        decoder_inputs = torch.cat((go_frame, mel_targets[:, :-1, :]), dim=1)\n",
    "        return decoder_inputs  # (batch_size, mel_length, num_mels)\n"
   ],
   "id": "c89e1df6a4a35611",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:29.032842Z",
     "start_time": "2024-11-19T15:57:17.298805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def Tacotron2Loss(mel_outputs, mel_outputs_postnet, mel_targets, stop_outputs, stop_targets, mel_mask):\n",
    "    # 마스킹 적용하여 손실 계산\n",
    "    mel_loss = F.mse_loss(mel_outputs[mel_mask], mel_targets[mel_mask])\n",
    "    mel_postnet_loss = F.mse_loss(mel_outputs_postnet[mel_mask], mel_targets[mel_mask])\n",
    "    stop_token_loss = F.binary_cross_entropy_with_logits(stop_outputs.squeeze(-1), stop_targets, reduction='none')\n",
    "    stop_token_loss = (stop_token_loss * mel_mask.squeeze(-1)).sum() / mel_mask.sum()\n",
    "\n",
    "    # 총 손실\n",
    "    total_loss = mel_loss + mel_postnet_loss + 0.1 * stop_token_loss\n",
    "    return total_loss"
   ],
   "id": "f77f6c5da3e4171b",
   "outputs": [],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:38.648801Z",
     "start_time": "2024-11-19T16:02:38.558316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Tacotron2(vocab_size=len(vocab)).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-6)"
   ],
   "id": "84198ca2ce47ba0e",
   "outputs": [],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T16:02:40.873306Z",
     "start_time": "2024-11-19T16:02:40.685392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 훈련 루프\n",
    "num_epochs = 3\n",
    "log_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, (text_inputs, input_lengths, mel_targets, mel_lengths) in enumerate(train_loader):\n",
    "        text_inputs = text_inputs.to(device)\n",
    "        input_lengths = input_lengths.to(device)\n",
    "        mel_targets = mel_targets.to(device)\n",
    "        mel_lengths = mel_lengths.to(device)\n",
    "\n",
    "        # 마스크 생성\n",
    "        mel_mask = get_mask_from_lengths(mel_lengths, max_len=mel_targets.size(1)).unsqueeze(-1).to(device)\n",
    "\n",
    "        # 스톱 토큰 타겟 생성\n",
    "        stop_targets = torch.zeros(mel_targets.size(0), mel_targets.size(1)).to(device)\n",
    "        for j, length in enumerate(mel_lengths):\n",
    "            stop_targets[j, length - 1:] = 1.0\n",
    "\n",
    "        # 모델 출력\n",
    "        mel_outputs, mel_outputs_postnet, stop_outputs = model(text_inputs, mel_targets, input_lengths)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = Tacotron2Loss(mel_outputs, mel_outputs_postnet, mel_targets, stop_outputs, stop_targets, mel_mask)\n",
    "\n",
    "        # 역전파 및 옵티마이저 스텝\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 로그 출력\n",
    "        if i % log_interval == 0:\n",
    "            print(f'Epoch: {epoch}, Step: {i}, Loss: {loss.item()}')\n"
   ],
   "id": "c872ba342192d2e6",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 2.0 or less. Got NumPy 2.1.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[173], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_epochs):\n\u001B[0;32m      6\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m----> 7\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_lengths\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmel_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmel_lengths\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_lengths\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43minput_lengths\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[167], line 27\u001B[0m, in \u001B[0;36mKSSDataset.__getitem__\u001B[1;34m(self, idx)\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m     26\u001B[0m     real_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]\n\u001B[1;32m---> 27\u001B[0m     item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43mreal_idx\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m     29\u001B[0m     \u001B[38;5;66;03m# 텍스트 처리 (컬럼명 수정)\u001B[39;00m\n\u001B[0;32m     30\u001B[0m     transcription \u001B[38;5;241m=\u001B[39m item[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moriginal_script\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:2762\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2760\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2761\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\arrow_dataset.py:2747\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2745\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2746\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[1;32m-> 2747\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2748\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2749\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2750\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:639\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    637\u001B[0m python_formatter \u001B[38;5;241m=\u001B[39m PythonFormatter(features\u001B[38;5;241m=\u001B[39mformatter\u001B[38;5;241m.\u001B[39mfeatures)\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m format_columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    641\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m format_columns:\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:403\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pa_table: pa\u001B[38;5;241m.\u001B[39mTable, query_type: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001B[0;32m    402\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrow\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 403\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_row\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    404\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_column(pa_table)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:444\u001B[0m, in \u001B[0;36mPythonFormatter.format_row\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m LazyRow(pa_table, \u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    443\u001B[0m row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_row(pa_table)\n\u001B[1;32m--> 444\u001B[0m row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_features_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_row\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m row\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\formatting\\formatting.py:222\u001B[0m, in \u001B[0;36mPythonFeaturesDecoder.decode_row\u001B[1;34m(self, row)\u001B[0m\n\u001B[0;32m    221\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_row\u001B[39m(\u001B[38;5;28mself\u001B[39m, row: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mdict\u001B[39m:\n\u001B[1;32m--> 222\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures \u001B[38;5;28;01melse\u001B[39;00m row\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:2044\u001B[0m, in \u001B[0;36mFeatures.decode_example\u001B[1;34m(self, example, token_per_repo_id)\u001B[0m\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_example\u001B[39m(\u001B[38;5;28mself\u001B[39m, example: \u001B[38;5;28mdict\u001B[39m, token_per_repo_id: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2031\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001B[39;00m\n\u001B[0;32m   2032\u001B[0m \n\u001B[0;32m   2033\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2041\u001B[0m \u001B[38;5;124;03m        `dict[str, Any]`\u001B[39;00m\n\u001B[0;32m   2042\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2044\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m{\u001B[49m\n\u001B[0;32m   2045\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2046\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_column_requires_decoding\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m   2047\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\n\u001B[0;32m   2048\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcolumn_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mzip_dict\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2049\u001B[0m \u001B[43m            \u001B[49m\u001B[43m{\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\n\u001B[0;32m   2050\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2051\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:2045\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m   2030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode_example\u001B[39m(\u001B[38;5;28mself\u001B[39m, example: \u001B[38;5;28mdict\u001B[39m, token_per_repo_id: Optional[Dict[\u001B[38;5;28mstr\u001B[39m, Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   2031\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001B[39;00m\n\u001B[0;32m   2032\u001B[0m \n\u001B[0;32m   2033\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2041\u001B[0m \u001B[38;5;124;03m        `dict[str, Any]`\u001B[39;00m\n\u001B[0;32m   2042\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   2044\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[1;32m-> 2045\u001B[0m         column_name: \u001B[43mdecode_nested_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeature\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2046\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_column_requires_decoding[column_name]\n\u001B[0;32m   2047\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m value\n\u001B[0;32m   2048\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m column_name, (feature, value) \u001B[38;5;129;01min\u001B[39;00m zip_dict(\n\u001B[0;32m   2049\u001B[0m             {key: value \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m example}, example\n\u001B[0;32m   2050\u001B[0m         )\n\u001B[0;32m   2051\u001B[0m     }\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\features.py:1405\u001B[0m, in \u001B[0;36mdecode_nested_example\u001B[1;34m(schema, obj, token_per_repo_id)\u001B[0m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(schema, (Audio, Image, Video)):\n\u001B[0;32m   1403\u001B[0m     \u001B[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001B[39;00m\n\u001B[0;32m   1404\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m schema\u001B[38;5;241m.\u001B[39mdecode:\n\u001B[1;32m-> 1405\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mschema\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_per_repo_id\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1406\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\datasets\\features\\audio.py:191\u001B[0m, in \u001B[0;36mAudio.decode_example\u001B[1;34m(self, value, token_per_repo_id)\u001B[0m\n\u001B[0;32m    189\u001B[0m array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mT\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmono:\n\u001B[1;32m--> 191\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mlibrosa\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_mono\u001B[49m(array)\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate \u001B[38;5;241m!=\u001B[39m sampling_rate:\n\u001B[0;32m    193\u001B[0m     array \u001B[38;5;241m=\u001B[39m librosa\u001B[38;5;241m.\u001B[39mresample(array, orig_sr\u001B[38;5;241m=\u001B[39msampling_rate, target_sr\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_rate)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:83\u001B[0m, in \u001B[0;36mattach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     81\u001B[0m submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     82\u001B[0m submod \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(submod_path)\n\u001B[1;32m---> 83\u001B[0m attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m     85\u001B[0m \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;241m==\u001B[39m attr_to_modules[name]:\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\lazy_loader\\__init__.py:82\u001B[0m, in \u001B[0;36mattach.<locals>.__getattr__\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m attr_to_modules:\n\u001B[0;32m     81\u001B[0m     submod_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpackage_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr_to_modules[name]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m---> 82\u001B[0m     submod \u001B[38;5;241m=\u001B[39m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubmod_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     83\u001B[0m     attr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(submod, name)\n\u001B[0;32m     85\u001B[0m     \u001B[38;5;66;03m# If the attribute lives in a file (module) with the same\u001B[39;00m\n\u001B[0;32m     86\u001B[0m     \u001B[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001B[39;00m\n\u001B[0;32m     87\u001B[0m     \u001B[38;5;66;03m# the module is accessible on the package.\u001B[39;00m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    124\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    125\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 126\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1204\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1147\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:690\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:940\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:241\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\librosa\\core\\audio.py:18\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msoxr\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mlazy\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m jit, stencil, guvectorize\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfft\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_fftlib\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconvert\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frames_to_samples, time_to_samples\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:59\u001B[0m\n\u001B[0;32m     54\u001B[0m             msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     55\u001B[0m                    \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscipy\u001B[38;5;241m.\u001B[39m__version__\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     56\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[1;32m---> 59\u001B[0m \u001B[43m_ensure_critical_deps\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;66;03m# END DO NOT MOVE\u001B[39;00m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_version\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_versions\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\numba\\__init__.py:45\u001B[0m, in \u001B[0;36m_ensure_critical_deps\u001B[1;34m()\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m numpy_version \u001B[38;5;241m>\u001B[39m (\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m     43\u001B[0m     msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumba needs NumPy 2.0 or less. Got NumPy \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     44\u001B[0m            \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumpy_version[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(msg)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: Numba needs NumPy 2.0 or less. Got NumPy 2.1."
     ]
    }
   ],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:42:43.945199Z",
     "start_time": "2024-11-19T14:42:43.938659Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def synthesize(model, text, vocab, max_decoder_steps=1000):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # 텍스트 전처리\n",
    "        sequence = text_to_sequence(text)\n",
    "        sequence = [vocab.get(char, vocab['<unk>']) for char in sequence]\n",
    "        text_inputs = torch.LongTensor(sequence).unsqueeze(0).to(device)\n",
    "        input_lengths = torch.LongTensor([len(sequence)]).to(device)\n",
    "\n",
    "        # 인코더\n",
    "        embedded_inputs = model.embedding(text_inputs)\n",
    "        encoder_outputs = model.encoder(embedded_inputs)\n",
    "\n",
    "        # 디코더 초기화\n",
    "        batch_size = 1\n",
    "        attention_hidden = torch.zeros(batch_size, 1024).to(device)\n",
    "        attention_cell = torch.zeros(batch_size, 1024).to(device)\n",
    "        decoder_hidden = torch.zeros(batch_size, 1024).to(device)\n",
    "        decoder_cell = torch.zeros(batch_size, 1024).to(device)\n",
    "        attention_context = torch.zeros(batch_size, 512).to(device)\n",
    "        mel_outputs = []\n",
    "        stop_outputs = []\n",
    "        decoder_input = torch.zeros(batch_size, 80).to(device)  # 시작 프레임\n",
    "\n",
    "        # 마스크 생성\n",
    "        memory_lengths = input_lengths\n",
    "        mask = ~get_mask_from_lengths(memory_lengths, max_len=encoder_outputs.size(1)).to(device)\n",
    "\n",
    "        for t in range(max_decoder_steps):\n",
    "            prenet_output = model.decoder.prenet(decoder_input)\n",
    "            attention_rnn_input = torch.cat((prenet_output, attention_context), dim=-1)\n",
    "            attention_hidden, attention_cell = model.decoder.attention_rnn(attention_rnn_input, (attention_hidden, attention_cell))\n",
    "            attention_context, attention_weights = model.decoder.attention_layer(attention_hidden, encoder_outputs, mask)\n",
    "            decoder_rnn_input = torch.cat((attention_hidden, attention_context), dim=-1)\n",
    "            decoder_hidden, decoder_cell = model.decoder.decoder_rnn(decoder_rnn_input, (decoder_hidden, decoder_cell))\n",
    "            decoder_output = torch.cat((decoder_hidden, attention_context), dim=-1)\n",
    "            mel_output = model.decoder.linear_projection(decoder_output)\n",
    "            stop_output = model.decoder.stop_projection(decoder_output)\n",
    "            mel_outputs.append(mel_output.unsqueeze(1))\n",
    "            stop_outputs.append(stop_output)\n",
    "\n",
    "            # 종료 조건 확인\n",
    "            if torch.sigmoid(stop_output) > 0.5:\n",
    "                break\n",
    "\n",
    "            decoder_input = mel_output\n",
    "\n",
    "        mel_outputs = torch.cat(mel_outputs, dim=1)  # (batch_size, time_steps, 80)\n",
    "        mel_outputs_postnet = mel_outputs + model.postnet(mel_outputs)\n",
    "        mel_outputs_postnet = mel_outputs_postnet.squeeze(0).cpu().numpy()\n",
    "        return mel_outputs_postnet\n"
   ],
   "id": "abe91be104860f46",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:43:49.502721Z",
     "start_time": "2024-11-19T14:42:50.587532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 예시: WaveGlow를 사용한 음성 합성\n",
    "# WaveGlow 모델 로드 (사전 학습된 모델 필요)\n",
    "waveglow = torch.hub.load('nvidia/DeepLearningExamples:torchhub', 'nvidia_waveglow').to(device)\n",
    "waveglow.eval()\n",
    "\n",
    "def mel_to_audio(mel):\n",
    "    mel = torch.from_numpy(mel).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        audio = waveglow.infer(mel)\n",
    "    audio = audio.cpu().numpy()[0]\n",
    "    return audio\n"
   ],
   "id": "bc8caf258a4a817f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Seungju\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
      "  warnings.warn(\n",
      "Downloading: \"https://github.com/nvidia/DeepLearningExamples/zipball/torchhub\" to C:\\Users\\Seungju/.cache\\torch\\hub\\torchhub.zip\n",
      "C:\\Users\\Seungju/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\Seungju/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "Downloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/waveglow_ckpt_fp32/versions/19.09.0/files/nvidia_waveglowpyt_fp32_20190427\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 예시: WaveGlow를 사용한 음성 합성\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# WaveGlow 모델 로드 (사전 학습된 모델 필요)\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m waveglow \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhub\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnvidia/DeepLearningExamples:torchhub\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnvidia_waveglow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      4\u001B[0m waveglow\u001B[38;5;241m.\u001B[39meval()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmel_to_audio\u001B[39m(mel):\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:647\u001B[0m, in \u001B[0;36mload\u001B[1;34m(repo_or_dir, model, source, trust_repo, force_reload, verbose, skip_validation, *args, **kwargs)\u001B[0m\n\u001B[0;32m    637\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m source \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgithub\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    638\u001B[0m     repo_or_dir \u001B[38;5;241m=\u001B[39m _get_cache_or_reload(\n\u001B[0;32m    639\u001B[0m         repo_or_dir,\n\u001B[0;32m    640\u001B[0m         force_reload,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    644\u001B[0m         skip_validation\u001B[38;5;241m=\u001B[39mskip_validation,\n\u001B[0;32m    645\u001B[0m     )\n\u001B[1;32m--> 647\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43m_load_local\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrepo_or_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    648\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\site-packages\\torch\\hub.py:676\u001B[0m, in \u001B[0;36m_load_local\u001B[1;34m(hubconf_dir, model, *args, **kwargs)\u001B[0m\n\u001B[0;32m    673\u001B[0m     hub_module \u001B[38;5;241m=\u001B[39m _import_module(MODULE_HUBCONF, hubconf_path)\n\u001B[0;32m    675\u001B[0m     entry \u001B[38;5;241m=\u001B[39m _load_entry_from_hubconf(hub_module, model)\n\u001B[1;32m--> 676\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mentry\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32m~/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\\PyTorch\\SpeechSynthesis\\Tacotron2\\waveglow\\entrypoints.py:95\u001B[0m, in \u001B[0;36mnvidia_waveglow\u001B[1;34m(pretrained, **kwargs)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     94\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://api.ngc.nvidia.com/v2/models/nvidia/waveglow_ckpt_fp32/versions/19.09.0/files/nvidia_waveglowpyt_fp32_20190427\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 95\u001B[0m ckpt_file \u001B[38;5;241m=\u001B[39m \u001B[43m_download_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_reload\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m ckpt \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(ckpt_file)\n\u001B[0;32m     97\u001B[0m state_dict \u001B[38;5;241m=\u001B[39m ckpt[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstate_dict\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~/.cache\\torch\\hub\\nvidia_DeepLearningExamples_torchhub\\PyTorch\\SpeechSynthesis\\Tacotron2\\waveglow\\entrypoints.py:73\u001B[0m, in \u001B[0;36m_download_checkpoint\u001B[1;34m(checkpoint, force_reload)\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(ckpt_file) \u001B[38;5;129;01mor\u001B[39;00m force_reload:\n\u001B[0;32m     72\u001B[0m     sys\u001B[38;5;241m.\u001B[39mstderr\u001B[38;5;241m.\u001B[39mwrite(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDownloading checkpoint from \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(checkpoint))\n\u001B[1;32m---> 73\u001B[0m     \u001B[43murllib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlretrieve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mckpt_file\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ckpt_file\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\urllib\\request.py:270\u001B[0m, in \u001B[0;36murlretrieve\u001B[1;34m(url, filename, reporthook, data)\u001B[0m\n\u001B[0;32m    267\u001B[0m     reporthook(blocknum, bs, size)\n\u001B[0;32m    269\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m--> 270\u001B[0m     block \u001B[38;5;241m=\u001B[39m \u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    271\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m block:\n\u001B[0;32m    272\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\http\\client.py:473\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[1;34m(self, amt)\u001B[0m\n\u001B[0;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[0;32m    471\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[0;32m    472\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[1;32m--> 473\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[0;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[0;32m    475\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[0;32m    476\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[1;34m(self, b)\u001B[0m\n\u001B[0;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[0;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\ssl.py:1314\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[1;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[0;32m   1310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1311\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1312\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m   1313\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[1;32m-> 1314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[1;32m~\\Python\\Python311\\Lib\\ssl.py:1166\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[1;34m(self, len, buffer)\u001B[0m\n\u001B[0;32m   1164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1167\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:51:22.800212Z",
     "start_time": "2024-11-19T14:51:22.786189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 텍스트 입력\n",
    "text = \"안녕하세요. 타코트론2 모델을 사용하여 음성을 합성합니다.\"\n",
    "\n",
    "# 멜 스펙트로그램 생성\n",
    "mel_output = synthesize(model, text, vocab)\n",
    "\n",
    "# 음성 신호로 변환\n",
    "audio = mel_to_audio(mel_output)\n",
    "\n",
    "# 오디오 저장\n",
    "import soundfile as sf\n",
    "sf.write('output.wav', audio, 22050)\n"
   ],
   "id": "9d382f7a609ab49e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[39], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m안녕하세요. 타코트론2 모델을 사용하여 음성을 합성합니다.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 멜 스펙트로그램 생성\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m mel_output \u001B[38;5;241m=\u001B[39m synthesize(\u001B[43mmodel\u001B[49m, text, vocab)\n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# 음성 신호로 변환\u001B[39;00m\n\u001B[0;32m      8\u001B[0m audio \u001B[38;5;241m=\u001B[39m mel_to_audio(mel_output)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.505320Z",
     "start_time": "2024-11-19T14:30:03.502600Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4250b24a4cc5aa8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.525007Z",
     "start_time": "2024-11-19T14:30:03.523388Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ec066cab232d6c64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.536047Z",
     "start_time": "2024-11-19T14:30:03.533017Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "af525ad577f01847",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.549992Z",
     "start_time": "2024-11-19T14:30:03.547200Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2639c24cfa35eacf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.571400Z",
     "start_time": "2024-11-19T14:30:03.568623Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e799bd98e563e75e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.613358Z",
     "start_time": "2024-11-19T14:30:03.610475Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "263d8006e8cd0936",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.638515Z",
     "start_time": "2024-11-19T14:30:03.635671Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8abed43dd493d3fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.661255Z",
     "start_time": "2024-11-19T14:30:03.659096Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9b9257745e915312",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.677280Z",
     "start_time": "2024-11-19T14:30:03.673520Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "46e0862426c2a910",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.690688Z",
     "start_time": "2024-11-19T14:30:03.688205Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ef0b940e59a73023",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.700482Z",
     "start_time": "2024-11-19T14:30:03.698170Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d527c90c7e3e1c43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.713835Z",
     "start_time": "2024-11-19T14:30:03.710840Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7264715b4883ba74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.732600Z",
     "start_time": "2024-11-19T14:30:03.729886Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7124fc487e43279a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.743535Z",
     "start_time": "2024-11-19T14:30:03.741655Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fd97132934df06ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.754200Z",
     "start_time": "2024-11-19T14:30:03.751473Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "40810ace72342b58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.776156Z",
     "start_time": "2024-11-19T14:30:03.773739Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e5b500aa4c7306c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.790381Z",
     "start_time": "2024-11-19T14:30:03.786758Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f757e957e3b6e4da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.811149Z",
     "start_time": "2024-11-19T14:30:03.808837Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1ad7a6fcaa780d7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.824417Z",
     "start_time": "2024-11-19T14:30:03.822173Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a9a9f107bde662e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.842712Z",
     "start_time": "2024-11-19T14:30:03.839364Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "6394a40d318a33a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.857325Z",
     "start_time": "2024-11-19T14:30:03.854613Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8fd407336e5e794e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.881271Z",
     "start_time": "2024-11-19T14:30:03.878802Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "361fdfc88f33e833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.900798Z",
     "start_time": "2024-11-19T14:30:03.898278Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "816b1df278d53598",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.929120Z",
     "start_time": "2024-11-19T14:30:03.926026Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9390d9f2370d524c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.939554Z",
     "start_time": "2024-11-19T14:30:03.936636Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "99f093c8c331bffe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.954995Z",
     "start_time": "2024-11-19T14:30:03.952834Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "adb01d6cd39899a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.968184Z",
     "start_time": "2024-11-19T14:30:03.965190Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8589175f69822517",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:03.984913Z",
     "start_time": "2024-11-19T14:30:03.981327Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "72d01024b185eade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.001190Z",
     "start_time": "2024-11-19T14:30:03.997989Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "33d4ad0f7450f0ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.012868Z",
     "start_time": "2024-11-19T14:30:04.010357Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d74b3bbe42c14e3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.046736Z",
     "start_time": "2024-11-19T14:30:04.043651Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "59e41f5d3d298174",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.056446Z",
     "start_time": "2024-11-19T14:30:04.053752Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4934fdaa32d9fd19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.069750Z",
     "start_time": "2024-11-19T14:30:04.066691Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4fad864a3c4f276c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.086263Z",
     "start_time": "2024-11-19T14:30:04.084020Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3e79056554abd901",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.095041Z",
     "start_time": "2024-11-19T14:30:04.092273Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "244961a1d7a23ad4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.105576Z",
     "start_time": "2024-11-19T14:30:04.103780Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "46c80111eadef08f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.115076Z",
     "start_time": "2024-11-19T14:30:04.113483Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "18595bdf111ab0e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.133175Z",
     "start_time": "2024-11-19T14:30:04.130332Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dbaac4c922769408",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.150862Z",
     "start_time": "2024-11-19T14:30:04.147454Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e2011c8f9d13a88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.166957Z",
     "start_time": "2024-11-19T14:30:04.164345Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "c578907f7c455380",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.196249Z",
     "start_time": "2024-11-19T14:30:04.192759Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff87c9d902ac91d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.227140Z",
     "start_time": "2024-11-19T14:30:04.224975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "dd8c5e542999d800",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.273373Z",
     "start_time": "2024-11-19T14:30:04.270658Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f77bc1c166976217",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.295324Z",
     "start_time": "2024-11-19T14:30:04.292382Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7a0b69240d38dd8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.326756Z",
     "start_time": "2024-11-19T14:30:04.323607Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4e0a150439ee7b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.358780Z",
     "start_time": "2024-11-19T14:30:04.356334Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "96e692fbbc5109da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.369788Z",
     "start_time": "2024-11-19T14:30:04.367268Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8aa28fdeb141c771",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.395442Z",
     "start_time": "2024-11-19T14:30:04.392033Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5020b59697ec2322",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.410299Z",
     "start_time": "2024-11-19T14:30:04.407021Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "94f299417a10a0c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.426015Z",
     "start_time": "2024-11-19T14:30:04.422401Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2173bb46b7a34303",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.437899Z",
     "start_time": "2024-11-19T14:30:04.434883Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "afbc22624f6f88d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.452177Z",
     "start_time": "2024-11-19T14:30:04.449436Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e513b4efb282571b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.464143Z",
     "start_time": "2024-11-19T14:30:04.462265Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b4f7992d6732f7af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.476394Z",
     "start_time": "2024-11-19T14:30:04.473955Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "943f83949359022b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.499896Z",
     "start_time": "2024-11-19T14:30:04.497301Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "396f7fc817997324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.510844Z",
     "start_time": "2024-11-19T14:30:04.507906Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9558663b3fef2e34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.525629Z",
     "start_time": "2024-11-19T14:30:04.522657Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ce7af6a19dbd0e8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.539335Z",
     "start_time": "2024-11-19T14:30:04.536849Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cc51c06b9582908d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.549643Z",
     "start_time": "2024-11-19T14:30:04.547314Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d16eff007c206676",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.561525Z",
     "start_time": "2024-11-19T14:30:04.558701Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "cb4c4a0e6817d6de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.571834Z",
     "start_time": "2024-11-19T14:30:04.568769Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d055dfc85c737d39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.581876Z",
     "start_time": "2024-11-19T14:30:04.579854Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "42173570ba991ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.594574Z",
     "start_time": "2024-11-19T14:30:04.590582Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2e82f1b5f7d632b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.606089Z",
     "start_time": "2024-11-19T14:30:04.603272Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8a3416c3ac2c8ce6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.623284Z",
     "start_time": "2024-11-19T14:30:04.620351Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "64704a3c12f5ce65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.647912Z",
     "start_time": "2024-11-19T14:30:04.645468Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e0fe426147d3d058",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.671045Z",
     "start_time": "2024-11-19T14:30:04.668614Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1166dc65f709d368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.688348Z",
     "start_time": "2024-11-19T14:30:04.685057Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1c75118194010572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.701701Z",
     "start_time": "2024-11-19T14:30:04.699337Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7c77839eb294c68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.716243Z",
     "start_time": "2024-11-19T14:30:04.713025Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "492751c2f7261690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.729717Z",
     "start_time": "2024-11-19T14:30:04.727627Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "214c7faade5b64fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.740144Z",
     "start_time": "2024-11-19T14:30:04.738305Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "bae7ffcd09d336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:30:04.755574Z",
     "start_time": "2024-11-19T14:30:04.752975Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "2a7a15f2fb4d3a80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "92442b371fd5de8a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
